{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_Feature_Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirabhop/Preclinical-AD-EEG-classification/blob/master/EEG_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHaci3VjhmI",
        "colab_type": "text"
      },
      "source": [
        "# **Library installation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa75w4oYjgtB",
        "colab_type": "code",
        "outputId": "c2749e1b-5020-45c8-8d53-1bb80cd8903d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#!pip install mne"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/19/e93e7ed3ecbafdb3a77164c0895de80afb159440cff72f5a62f57b8c1c4a/mne-0.20.1-py3-none-any.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.3)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.20.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33aNObJVkSiG",
        "colab_type": "code",
        "outputId": "d4dc9c7a-3e10-44cb-fa70-03a8816dab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#pip install git+https://github.com/raphaelvallat/entropy.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/raphaelvallat/entropy.git\n",
            "  Cloning https://github.com/raphaelvallat/entropy.git to /tmp/pip-req-build-xv40ru8x\n",
            "  Running command git clone -q https://github.com/raphaelvallat/entropy.git /tmp/pip-req-build-xv40ru8x\n",
            "Building wheels for collected packages: entropy\n",
            "  Building wheel for entropy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for entropy: filename=entropy-0.1.1-cp36-none-any.whl size=15459 sha256=6bab14deadaaa795c410d024e81bc1b4a57b4a60deb1c628abbaee344a121d3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l6fe4h65/wheels/60/ed/d3/b715e38438f1f39edb1383aea79c578073953b25fa576fc71e\n",
            "Successfully built entropy\n",
            "Installing collected packages: entropy\n",
            "Successfully installed entropy-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVLaPZMma7NG",
        "colab_type": "code",
        "outputId": "da94f88d-82ce-4b8d-e53f-3f8b02efe23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#pip install git+https://github.com/nice-tools/nice.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nice-tools/nice.git\n",
            "  Cloning https://github.com/nice-tools/nice.git to /tmp/pip-req-build-1t9r4ol4\n",
            "  Running command git clone -q https://github.com/nice-tools/nice.git /tmp/pip-req-build-1t9r4ol4\n",
            "Building wheels for collected packages: nice\n",
            "  Building wheel for nice (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nice: filename=nice-0.1.dev0-cp36-none-any.whl size=53945 sha256=9cc5064280ecec8fbf7e95f4b74a7bad9b654de8538114c76c7df9eca01087e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ltczx9ef/wheels/50/a0/a3/2d473364ff7f9fdd3d41b0da4b4e34ef98c713cfa30695c2b0\n",
            "Successfully built nice\n",
            "Installing collected packages: nice\n",
            "Successfully installed nice-0.1.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8LXIte0RrV9",
        "colab_type": "text"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dngxH8LlkxQT",
        "colab_type": "text"
      },
      "source": [
        "### **1) Power Spectral Density (PSD)** x5\n",
        "*Delta (1-4Hz), Theta (4-8Hz), Alpha (8-12Hz), Beta (12-30Hz), Gamma (30-45Hz; Gaubert et al., 2019)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDNW6FBhbslb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def psd(data, method):\n",
        "  from nice.markers.spectral import psd_welch\n",
        "  import numpy as np\n",
        "\n",
        "  psd_delta, freq_delta   = psd_welch(data, fmin = 0, fmax = 4)\n",
        "  psd_theta, freq_theta   = psd_welch(data, fmin = 4, fmax = 8)\n",
        "  psd_alpha, freq_alpha   = psd_welch(data, fmin = 8, fmax = 12)\n",
        "  psd_beta, freq_beta     = psd_welch(data, fmin = 12, fmax = 30)\n",
        "  psd_gamma, freq_gamma   = psd_welch(data, fmin = 30, fmax = 46)\n",
        "\n",
        "  if method == 'mean':\n",
        "    psds_m_d = np.mean(psd_delta)\n",
        "    psds_m_th = np.mean(psd_theta)\n",
        "    psds_m_al = np.mean(psd_alpha)\n",
        "    psds_m_be = np.mean(psd_beta)\n",
        "    psds_m_gm = np.mean(psd_gamma)\n",
        "  elif method == 'median':\n",
        "    psds_m_d = np.median(psd_delta)\n",
        "    psds_m_th = np.median(psd_theta)\n",
        "    psds_m_al = np.median(psd_alpha)\n",
        "    psds_m_be = np.median(psd_beta)\n",
        "    psds_m_gm = np.median(psd_gamma)\n",
        "  elif method == 'None':\n",
        "    psds_m_d = (psd_delta)\n",
        "    psds_m_th = (psd_theta)\n",
        "    psds_m_al = (psd_alpha)\n",
        "    psds_m_be = (psd_beta)\n",
        "    psds_m_gm = (psd_gamma)\n",
        "  psd_list = [psds_m_d, psds_m_th, psds_m_al, psds_m_be, psds_m_gm]\n",
        "  return psd_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvcf0_mg8ZqW",
        "colab_type": "text"
      },
      "source": [
        "### **2) Median Spectral Frequency (MSF)** x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTlTamcF8eEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSF(data):\n",
        "  from mne.time_frequency import psd_welch\n",
        "  import numpy as np\n",
        "\n",
        "  psd_total, freq_total = psd_welch(data, fmin = 0, fmax = 40)\n",
        "  psd_m_total = np.median(psd_total)\n",
        "  return psd_m_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4eWQ3Wp_uFq",
        "colab_type": "text"
      },
      "source": [
        "### **3) Spectral Entropy (SE)** x1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4SZhTUEMEg0",
        "colab_type": "text"
      },
      "source": [
        "Using [Shannon entropy of the PSD of data (Inouye, T. et al. (1991)](https://raphaelvallat.com/entropy/build/html/generated/entropy.spectral_entropy.html#entropy.spectral_entropy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzq3cX6oCk9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SpectralEntropy(data):\n",
        "  import entropy\n",
        "  import numpy as np\n",
        "\n",
        "  #Convert mne object to dataframe\n",
        "  #ch_names = ['Fp1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3',\n",
        "   #         'O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8',\n",
        "    #        'AF4','Fp2','Fz','Cz'] #32 electrodes\n",
        "  df = data.to_data_frame(index = None)\n",
        "\n",
        "  #Convert dataframe to array\n",
        "  for x in data.info['ch_names']:\n",
        "    array = np.array(df[x])\n",
        "    array = np.concatenate([array, array])\n",
        "\n",
        "  #Calculate entropy\n",
        "  Spectral_Entropy = entropy.spectral_entropy(array, sf = 1000, method = 'welch')\n",
        "  return Spectral_Entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FtekCN8Mjpx",
        "colab_type": "text"
      },
      "source": [
        "### **4) Algorithmic Complexity (AC)** x1\n",
        "Estimated using Kolmogorov Complexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4BAxfFbb1NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AlgorithmicComplexity(data):\n",
        "  from nice.algorithms.information_theory import epochs_compute_komplexity\n",
        "  import math\n",
        "  import pandas as pd\n",
        "  \n",
        "  #nbins = Number of bins to use for symbolic transformation\n",
        "  #Only {0,1,2,3,4,5,6,7,8,9} so n = 10 -> the bit would be log2_10\n",
        "  AC = epochs_compute_komplexity(data, nbins = math.log2(10))\n",
        "  AC = pd.DataFrame(AC).mean().mean()\n",
        "  return AC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mEsDFDCQh9A",
        "colab_type": "text"
      },
      "source": [
        "### **5) Functional Connectivity (wSMI)** x2\n",
        " weighted mutual symbolic information (wSMI) were summarized by calculating the median value from each electrodes\n",
        "1.   wSMI of theta \n",
        "2.   wSMI of alpha\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EdROfbIyv3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wSMI(data, method):\n",
        "  from nice.algorithms.connectivity import epochs_compute_wsmi\n",
        "  from mne import filter\n",
        "  import mne\n",
        "  import numpy as np\n",
        "\n",
        "  #Filter data\n",
        "  raw_theta = data\n",
        "  raw_theta.filter(l_freq = 4, h_freq = 8)\n",
        "  raw_alpha = data\n",
        "  raw_alpha.filter(l_freq = 8, h_freq = 12)\n",
        "\n",
        "  trigger = ('Status')\n",
        "  events = mne.find_events(data, stim_channel=trigger)\n",
        "\n",
        "  #Epoching\n",
        "  data_theta = mne.Epochs(raw_theta, events , preload = True)\n",
        "  data_alpha = mne.Epochs(raw_alpha, events , preload = True)\n",
        "\n",
        "  #wSMI\n",
        "  wsmi_t, smi_t, sym_t, count_t = epochs_compute_wsmi(data_theta, kernel = 3, tau = 21, method_params = {'bypass_csd': True})\n",
        "  wsmi_a, smi_a, sym_a, count_a = epochs_compute_wsmi(data_alpha, kernel = 3, tau = 41, method_params = {'bypass_csd': True})\n",
        "  \n",
        "  #Method\n",
        "  if method == 'mean':\n",
        "    wsmi = [np.mean(wsmi_t), np.mean(wsmi_a)]\n",
        "  elif method == 'median':\n",
        "    wsmi = [np.median(wsmi_t), np.median(wsmi_a)]\n",
        "  return wsmi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG9S2rA38EOE",
        "colab_type": "text"
      },
      "source": [
        "# **Buiding DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fmjegtsy1qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_eeg_features(subjectID):\n",
        "  import mne\n",
        "\n",
        "  EEG_feature_names = ['id', 'PSD_Delta', 'PSD_Theta', 'PSD_Alpha', 'PSD_Beta', 'PSD_Gamma', 'MSF', 'SE', 'AC', 'wSMI_Alpha', 'wSMI_Theta']\n",
        "  df = pd.DataFrame(None, columns = EEG_feature_names)\n",
        "\n",
        "  from mne.preprocessing import compute_proj_eog\n",
        "\n",
        "  os.chdir('/content/drive/My Drive/EEG Data')\n",
        "  \n",
        "  eog_chs = ('Leye','Reye','UBlink','DBlink','LMast','RMast')\n",
        "  trigger = ('Status')\n",
        "  #Exclude; Gsr = Skin conductance, Resp = Respiration belt, Plet = plethismograph (Blood pressure, HR), Temp = thermometer\n",
        "  exclude_chs = ('EXG7','EXG8','GSR1','GSR2','Erg1','Erg2','Resp','Plet','Temp') \n",
        "  subjects = ('SS1', 'SS2', 'SS3', 'SS4', 'SS5', 'SS6', 'SS7', 'SS8')\n",
        "  chn_names = ['Fp1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3',\n",
        "               'Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8',\n",
        "               'FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
        "\n",
        "  #Subject ID expected to be list\n",
        "  for SS in subjectID:\n",
        "    #Import\n",
        "    if SS in ['SS1', 'SS2', 'SS3']:\n",
        "        raw = mne.io.read_raw_fif(SS+'.fif', preload = True)\n",
        "    else:\n",
        "        raw = mne.io.read_raw_bdf(SS+'.bdf', exclude = exclude_chs, eog = eog_chs, stim_channel = trigger, preload = True)\n",
        "        \n",
        "    #Filter\n",
        "    raw.filter(l_freq = 0.5, h_freq = 45)\n",
        "    raw.notch_filter(freqs = (50, 100))\n",
        "\n",
        "    #Denosing SSP\n",
        "    eog_projs, _ = compute_proj_eog(raw, n_eeg = 1, reject=None, no_proj=True)\n",
        "    raw.add_proj(eog_projs)\n",
        "\n",
        "    #Epoching\n",
        "    events = mne.find_events(raw, stim_channel=trigger)\n",
        "    epoch = mne.Epochs(raw, events, preload = True)\n",
        "\n",
        "    #5 fetures\n",
        "    features = {'id': None, 'PSD_Delta': None, 'PSD_Theta': None, 'PSD_Alpha': None, 'PSD_Beta': None,\n",
        "                'PSD_Gamma': None, 'MSF': None, 'SE': None, 'AC': None, 'wSMI_Alpha': None, 'wSMI_Theta': None}    \n",
        "    psd_total = psd(epoch, 'median')\n",
        "\n",
        "    features['id'] = SS\n",
        "    features['PSD_Delta'] = psd_total[0]\n",
        "    features['PSD_Theta'] = psd_total[1]\n",
        "    features['PSD_Alpha'] = psd_total[2]\n",
        "    features['PSD_Beta'] = psd_total[3]\n",
        "    features['PSD_Gamma'] = psd_total[4]\n",
        "    features['MSF'] = MSF(epoch)\n",
        "    features['SE'] = SpectralEntropy(epoch)\n",
        "    features['AC'] = AlgorithmicComplexity(epoch)\n",
        "\n",
        "    wSMI_total = wSMI(raw, 'mean')\n",
        "    features['wSMI_Theta'] = wSMI_total[0]\n",
        "    features['wSMI_Alpha'] = wSMI_total[1]\n",
        "\n",
        "    #Build DataFrame\n",
        "    df = df.append(features, ignore_index = True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy9Gc8dEVcfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_df_ss(data):\n",
        "  from mne.time_frequency import psd_welch\n",
        "\n",
        "  for chn in chn_names:\n",
        "    psd_df.loc[0, chn]= (psd_welch(data, 0, 4, picks = chn))[0][0][0]\n",
        "    psd_df.loc[1, chn] = (psd_welch(data, 4, 8, picks = chn))[0][0][0]\n",
        "    psd_df.loc[2, chn] = (psd_welch(data, 8, 12, picks = chn))[0][0][0]\n",
        "    psd_df.loc[3, chn] = (psd_welch(data, 12, 30, picks = chn))[0][0][0]\n",
        "    psd_df.loc[4, chn] = (psd_welch(data, 30, 45, picks = chn))[0][0][0]\n",
        "  return psd_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHvSo0fvTajN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_psd_sorce(subjects):\n",
        "  from mne.time_frequency import psd_welch\n",
        "  from mne.preprocessing import compute_proj_eog\n",
        "\n",
        "  import pandas as pd\n",
        "  import mne\n",
        "  import os\n",
        "\n",
        "  os.chdir('/content/drive/My Drive/EEG Data')\n",
        "\n",
        "  eog_chs = ('Leye','Reye','UBlink','DBlink','LMast','RMast')\n",
        "  trigger = ('Status')\n",
        "  #Exclude; Gsr = Skin conductance, Resp = Respiration belt, Plet = plethismograph (Blood pressure, HR), Temp = thermometer\n",
        "  exclude_chs = ('EXG7','EXG8','GSR1','GSR2','Erg1','Erg2','Resp','Plet','Temp') \n",
        "  chn_names = ['Fp1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3',\n",
        "               'Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8',\n",
        "               'FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
        "  df = pd.DataFrame()\n",
        "  for SS in subjects:\n",
        "    if SS in ['SS1', 'SS2', 'SS3']:\n",
        "        raw = mne.io.read_raw_fif(SS+'.fif', preload = True)\n",
        "    \n",
        "    else:\n",
        "        raw = mne.io.read_raw_bdf(SS+'.bdf', exclude = exclude_chs, eog = eog_chs, stim_channel = trigger, preload = True)\n",
        "    \n",
        "    #Filter\n",
        "    raw.filter(l_freq = 0.5, h_freq = 45)\n",
        "    raw.notch_filter(freqs = (50, 100))\n",
        "\n",
        "    #Denosing SSP\n",
        "    eog_projs, _ = compute_proj_eog(raw, n_eeg = 1, reject=None, no_proj=True)\n",
        "    raw.add_proj(eog_projs)\n",
        "\n",
        "    df_ss = get_df_ss(raw)\n",
        "    df = pd.concat((df, df_ss))\n",
        "    \n",
        "    by_row_index = df.groupby(df.index)\n",
        "    df_means_psd = by_row_index.mean()\n",
        "  return df_means_psd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUAaAfKFm-av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57500d41-da7c-4f58-9f6f-08adb45a1a9b"
      },
      "source": [
        "print('updated 25/4/2020, 11.43')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updated 25/4/2020, 11.43\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}